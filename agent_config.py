#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
LiveKit Agenté…ç½® - æ„å»ºå¤šè¯­è¨€ç¿»è¯‘ä»£ç†
ç¬¦åˆLiveKit Agents 1.1.7 APIè§„èŒƒ
"""

import os
import logging
from livekit.agents import Agent, AgentSession, llm
from livekit.plugins import deepgram, cartesia, silero
from typing import Dict, Any, Tuple, AsyncIterator
from groq import Groq
import asyncio

# é…ç½®æ—¥å¿—
logger = logging.getLogger("agent-config")

# è¯­è¨€é…ç½®
LANGUAGE_CONFIG = {
    "ja": {
        "name": "æ—¥è¯­",
        "voice_id": "95856005-0332-41b0-935f-352e296aa0df",  # Cartesiaæ—¥è¯­voice ID
        "deepgram_model": "nova-2",  # ä½¿ç”¨æ ‡å‡†nova-2æ¨¡å‹
    },
    "ko": {
        "name": "éŸ©è¯­", 
        "voice_id": "7d787990-4c3a-4766-9450-8c3ac6718b13",  # CartesiaéŸ©è¯­voice ID
        "deepgram_model": "nova-2",  # ä½¿ç”¨æ ‡å‡†nova-2æ¨¡å‹
    },
    "vi": {
        "name": "è¶Šå—è¯­",
        "voice_id": "f9836c6e-a0bd-460e-9d3c-f7299fa60f94",  # Cartesiaè¶Šå—è¯­voice ID  
        "deepgram_model": "nova-2",  # ä½¿ç”¨æ ‡å‡†nova-2æ¨¡å‹
    },
    "ms": {
        "name": "é©¬æ¥è¯­",
        "voice_id": "7d787990-4c3a-4766-9450-8c3ac6718b13",  # ä½¿ç”¨è‹±è¯­voiceä½œä¸ºé©¬æ¥è¯­
        "deepgram_model": "nova-2",  # ä½¿ç”¨æ ‡å‡†nova-2æ¨¡å‹
    }
}

# æºè¯­è¨€é…ç½®ï¼ˆè®²è€…è¯­è¨€ï¼‰
SOURCE_LANGUAGE = "zh"  # ä¸­æ–‡

class CustomGroqLLM(llm.LLM):
    """
    è‡ªå®šä¹‰Groq LLMå®ç°ï¼Œä½¿ç”¨å®˜æ–¹groqå®¢æˆ·ç«¯
    """
    
    def __init__(self, model: str = "llama3-8b-8192"):
        super().__init__()
        self._model = model
        self._client = Groq(api_key=os.environ["GROQ_API_KEY"])
        logger.info(f"ğŸ§  åˆå§‹åŒ–å®˜æ–¹Groqå®¢æˆ·ç«¯ - æ¨¡å‹: {model}")
    
    def chat(
        self,
        *,
        chat_ctx: llm.ChatContext,
        tools: list | None = None,
        tool_choice: str | None = None,
        conn_options: dict | None = None,
        temperature: float | None = None,
        n: int | None = None,
    ) -> "llm.LLMStream":
        """
        å‘é€èŠå¤©è¯·æ±‚åˆ°Groq
        æ”¯æŒLiveKit Agents 1.1.7çš„å®Œæ•´å‚æ•°ç­¾å
        """
        logger.info(f"ğŸ§  Groq chatè°ƒç”¨ - tools: {len(tools) if tools else 0}, tool_choice: {tool_choice}")
        
        return CustomGroqLLMStream(
            client=self._client,
            model=self._model,
            chat_ctx=chat_ctx,
            tools=tools,
            tool_choice=tool_choice,
            temperature=temperature or 0.7,
        )

class CustomGroqLLMStream(llm.LLMStream):
    """
    è‡ªå®šä¹‰Groq LLMæµå®ç°
    å®ç°LiveKit Agents 1.1.7 LLMStreamæŠ½è±¡æ–¹æ³•
    """
    
    def __init__(
        self,
        client: Groq,
        model: str,
        chat_ctx: llm.ChatContext,
        tools: list | None = None,
        tool_choice: str | None = None,
        temperature: float = 0.7,
    ):
        super().__init__(chat_ctx=chat_ctx)
        self._client = client
        self._model = model
        self._temperature = temperature
        self._tools = tools
        self._tool_choice = tool_choice
        
    async def _run(self) -> AsyncIterator[llm.ChatChunk]:
        """
        å®ç°LiveKit Agents 1.1.7è¦æ±‚çš„_runæŠ½è±¡æ–¹æ³•
        è¿”å›ChatChunkå¼‚æ­¥ç”Ÿæˆå™¨ç”¨äºæµå¼å“åº”
        """
        try:
            # è½¬æ¢ChatContextä¸ºGroq APIæ ¼å¼
            messages = []
            for msg in self._chat_ctx.messages:
                if hasattr(msg, 'role') and hasattr(msg, 'content'):
                    messages.append({
                        "role": msg.role,
                        "content": msg.content
                    })
            
            logger.info(f"ğŸ§  å‘é€è¯·æ±‚åˆ°Groq: {len(messages)} æ¡æ¶ˆæ¯")
            if messages:
                logger.info(f"ğŸ§  ç”¨æˆ·è¾“å…¥: '{messages[-1]['content'][:100]}...'")
            
            # å‡†å¤‡APIè°ƒç”¨å‚æ•°
            api_params = {
                "model": self._model,
                "messages": messages,
                "temperature": self._temperature,
                "max_tokens": 1000,
                "stream": True,  # å¯ç”¨æµå¼æ¨¡å¼
            }
            
            # æ·»åŠ toolsæ”¯æŒï¼ˆå¦‚æœæä¾›ï¼‰
            if self._tools:
                logger.info(f"ğŸ”§ ä½¿ç”¨å·¥å…·: {len(self._tools)} ä¸ª")
                # æ³¨æ„ï¼šGroqå¯èƒ½ä¸æ”¯æŒæ‰€æœ‰å·¥å…·åŠŸèƒ½ï¼Œè¿™é‡Œå…ˆè®°å½•
                logger.warning("âš ï¸ Groqå·¥å…·æ”¯æŒæœ‰é™ï¼Œä»…ç”¨äºç¿»è¯‘ä»»åŠ¡")
            
            if self._tool_choice:
                logger.info(f"ğŸ¯ å·¥å…·é€‰æ‹©: {self._tool_choice}")
            
            # è°ƒç”¨å®˜æ–¹Groqå®¢æˆ·ç«¯æµå¼API
            logger.info(f"ğŸ“¡ è°ƒç”¨Groqæµå¼API - æ¨¡å‹: {self._model}")
            stream = self._client.chat.completions.create(**api_params)
            
            # å¤„ç†æµå¼å“åº”
            full_content = ""
            for chunk in stream:
                if chunk.choices:
                    choice = chunk.choices[0]
                    if hasattr(choice, 'delta') and choice.delta:
                        # å¤„ç†æµå¼deltaå†…å®¹
                        delta_content = choice.delta.content or ""
                        full_content += delta_content
                        
                        if delta_content:
                            logger.debug(f"ğŸ”„ Groqæµå¼ç‰‡æ®µ: '{delta_content}'")
                            
                            # åˆ›å»ºç¬¦åˆLiveKitæ ¼å¼çš„ChatChunk
                            # ä½¿ç”¨æ­£ç¡®çš„ChatChunkæ„é€ æ–¹å¼
                            chat_chunk = llm.ChatChunk(
                                request_id=getattr(chunk, 'id', ''),
                                choices=[
                                    llm.Choice(
                                        delta=llm.ChoiceDelta(
                                            content=delta_content,
                                            role="assistant"
                                        )
                                    )
                                ]
                            )
                            yield chat_chunk
            
            logger.info(f"ğŸŒ Groqå®Œæ•´ç¿»è¯‘ç»“æœ: '{full_content}'")
            
        except Exception as e:
            logger.error(f"âŒ Groq LLMæµå¼å¤„ç†å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
            raise

def get_translation_instructions(language: str) -> str:
    """
    è·å–æŒ‡å®šè¯­è¨€çš„ç¿»è¯‘æŒ‡ä»¤
    
    Args:
        language: ç›®æ ‡è¯­è¨€ä»£ç 
        
    Returns:
        ç¿»è¯‘æŒ‡ä»¤å­—ç¬¦ä¸²
    """
    if language not in LANGUAGE_CONFIG:
        raise ValueError(f"ä¸æ”¯æŒçš„è¯­è¨€ä»£ç : {language}ï¼Œæ”¯æŒçš„è¯­è¨€: {list(LANGUAGE_CONFIG.keys())}")
    
    language_info = LANGUAGE_CONFIG.get(language, {})
    language_name = language_info.get("name", language)
    
    return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®æ—¶ç¿»è¯‘åŠ©æ‰‹ï¼Œä¸“é—¨å°†ä¸­æ–‡ç¿»è¯‘æˆ{language_name}ã€‚

æ ¸å¿ƒèŒè´£ï¼š
1. å®æ—¶ç¿»è¯‘ä¸­æ–‡è¯­éŸ³åˆ°{language_name}
2. ä¿æŒç¿»è¯‘çš„å‡†ç¡®æ€§å’Œè‡ªç„¶æµç•…æ€§
3. ä¿ç•™åŸæ–‡çš„è¯­æ°”å’Œæ„å›¾

ç¿»è¯‘è§„åˆ™ï¼š
- ç›´æ¥è¾“å‡º{language_name}ç¿»è¯‘ç»“æœï¼Œä¸è¦æ·»åŠ "ç¿»è¯‘ï¼š"ç­‰å‰ç¼€
- ä¿æŒå£è¯­åŒ–å’Œè‡ªç„¶çš„è¡¨è¾¾æ–¹å¼  
- å¯¹äºä¸“ä¸šæœ¯è¯­ä¿æŒå‡†ç¡®æ€§
- å¦‚æœéŸ³é¢‘ä¸æ¸…æ™°ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­æœ€å¯èƒ½çš„æ„æ€
- ä¿æŒåŸæ–‡çš„æƒ…æ„Ÿè‰²å½©å’Œè¯­æ°”

è¯·å§‹ç»ˆç”¨{language_name}å›åº”ï¼Œæä¾›å‡†ç¡®ä¸”è‡ªç„¶çš„ç¿»è¯‘ã€‚"""

def create_translation_components(language: str) -> Tuple[Any, Any, Any, Any]:
    """
    ä¸ºæŒ‡å®šè¯­è¨€åˆ›å»ºç¿»è¯‘ç»„ä»¶
    
    Args:
        language: ç›®æ ‡è¯­è¨€ä»£ç 
        
    Returns:
        (vad, stt, llm, tts) ç»„ä»¶å…ƒç»„
    """
    if language not in LANGUAGE_CONFIG:
        raise ValueError(f"ä¸æ”¯æŒçš„è¯­è¨€ä»£ç : {language}ï¼Œæ”¯æŒçš„è¯­è¨€: {list(LANGUAGE_CONFIG.keys())}")
    
    language_info = LANGUAGE_CONFIG[language]
    language_name = language_info["name"]
    
    logger.info(f"ğŸ”§ å¼€å§‹åˆ›å»º {language_name} ç¿»è¯‘ç»„ä»¶...")
    
    # VADç»„ä»¶ - è¯­éŸ³æ´»åŠ¨æ£€æµ‹
    try:
        logger.info(f"ğŸ¤ åˆå§‹åŒ–VAD (Silero)...")
        vad = silero.VAD.load()
        logger.info(f"âœ… VADåˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ VADåˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    
    # STTé…ç½® - è®¾ç½®ä¸ºæºè¯­è¨€ï¼ˆä¸­æ–‡ï¼‰
    try:
        logger.info(f"ğŸ—£ï¸ åˆå§‹åŒ–STT (Deepgram nova-2)...")
        stt = deepgram.STT(
            model="nova-2",  # ä¸­æ–‡æ¨¡å‹
            language="zh",
        )
        logger.info(f"âœ… STTåˆå§‹åŒ–æˆåŠŸ - æ¨¡å‹: nova-2, è¯­è¨€: zh")
    except Exception as e:
        logger.error(f"âŒ STTåˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    
    # LLMé…ç½® - ä½¿ç”¨è‡ªå®šä¹‰Groqå®¢æˆ·ç«¯
    try:
        logger.info(f"ğŸ§  åˆå§‹åŒ–è‡ªå®šä¹‰Groq LLM (llama3-8b-8192)...")
        llm_instance = CustomGroqLLM(model="llama3-8b-8192")
        logger.info(f"âœ… è‡ªå®šä¹‰Groq LLMåˆå§‹åŒ–æˆåŠŸ - æ¨¡å‹: llama3-8b-8192")
    except Exception as e:
        logger.error(f"âŒ è‡ªå®šä¹‰Groq LLMåˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    
    # TTSé…ç½® - è®¾ç½®ä¸ºç›®æ ‡è¯­è¨€
    try:
        logger.info(f"ğŸ”Š åˆå§‹åŒ–TTS (Cartesia {language_name})...")
        tts = cartesia.TTS(
            model="sonic-multilingual",  # ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹
            voice=language_info["voice_id"],
        )
        logger.info(f"âœ… TTSåˆå§‹åŒ–æˆåŠŸ - æ¨¡å‹: sonic-multilingual, è¯­éŸ³ID: {language_info['voice_id']}")
    except Exception as e:
        logger.error(f"âŒ TTSåˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    
    logger.info(f"ğŸ‰ {language_name} ç¿»è¯‘ç»„ä»¶åˆ›å»ºå®Œæˆ!")
    return vad, stt, llm_instance, tts

def create_translation_agent(language: str) -> Agent:
    """
    ä¸ºæŒ‡å®šè¯­è¨€åˆ›å»ºç¿»è¯‘Agentï¼ˆä»…åŒ…å«æŒ‡ä»¤ï¼‰
    
    Args:
        language: ç›®æ ‡è¯­è¨€ä»£ç 
        
    Returns:
        é…ç½®å¥½çš„Agentå®ä¾‹
    """
    if language not in LANGUAGE_CONFIG:
        raise ValueError(f"ä¸æ”¯æŒçš„è¯­è¨€ä»£ç : {language}ï¼Œæ”¯æŒçš„è¯­è¨€: {list(LANGUAGE_CONFIG.keys())}")
    
    language_name = LANGUAGE_CONFIG[language]["name"]
    logger.info(f"ğŸ¤– åˆ›å»º {language_name} Agentæ¡†æ¶...")
    
    # åˆ›å»ºAgentï¼ŒåªåŒ…å«æŒ‡ä»¤ï¼Œä¸è®¾ç½®ç»„ä»¶
    agent = Agent(
        instructions=get_translation_instructions(language)
    )
    
    logger.info(f"âœ… {language_name} Agentæ¡†æ¶åˆ›å»ºæˆåŠŸ")
    return agent 
